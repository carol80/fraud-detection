{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import *\n",
    "from sklearn.dummy import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.calibration import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.svm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "text  0\n",
       "spam  0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: met office presentation . . .  vince ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: marketpoint business plan summary  vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: yen outlook  vince ,  as a followup t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: enron projects by team  enron tiger t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: mg metals : quant analysis &amp; risk  hi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: met office presentation . . .  vince ...     0\n",
       "1  Subject: marketpoint business plan summary  vi...     0\n",
       "2  Subject: yen outlook  vince ,  as a followup t...     0\n",
       "3  Subject: enron projects by team  enron tiger t...     0\n",
       "4  Subject: mg metals : quant analysis & risk  hi...     0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56622\n"
     ]
    }
   ],
   "source": [
    "lmtzr = WordNetLemmatizer()\n",
    "with open('english.txt', 'r') as f:\n",
    "  text = f.readlines()\n",
    "eng_words_ubuntu = set([lmtzr.lemmatize(x.strip().lower().replace('\\'s', '')) for x in text] )\n",
    "stopwords = set(stopwords.words('english'))\n",
    "words = eng_words_ubuntu.difference(stopwords)\n",
    "print(len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = re.sub('[^a-zA-Z0-9]+', ' ',df['text'][0])\n",
    "tr = tr.lower().split()\n",
    "tr = ' '.join(list(filter(lambda text:text in words,tr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject met office presentation vince keep informed european effort steve good job taking bull asked rapidly build client base associated support system looking good mike forwarded mike enron north america corp stephen bennett enron annette harris lon tony hamilton enron enron mike jose marquez corp enron enron subject met office presentation annette wanted drop quick line thank invitation met presentation today tony currently trying get grasp require way weather information building support structure need close met office well data information presented today helpful like take little time sit whose weather driven like get feel data already streaming get idea utilize supplement data europe model created houston start want make sure tailor would like take time sit chat perhaps tony take others lunch afternoon coffee thanks help stephen bennett senior meteorologist enron research london april tony hamilton meteorology manager enron research'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda text:re.sub('[^a-zA-Z0-9]+', ' ',text)).apply(lambda x: (x.lower()).split())\n",
    "df['text']= df['text'].apply(lambda text_list:' '.join(list(filter(lambda text:text in words,text_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject met office presentation vince keep informed european effort steve good job taking bull asked rapidly build client base associated support system looking good mike forwarded mike enron north america corp stephen bennett enron annette harris lon tony hamilton enron enron mike jose marquez corp enron enron subject met office presentation annette wanted drop quick line thank invitation met presentation today tony currently trying get grasp require way weather information building support structure need close met office well data information presented today helpful like take little time sit whose weather driven like get feel data already streaming get idea utilize supplement data europe model created houston start want make sure tailor would like take time sit chat perhaps tony take others lunch afternoon coffee thanks help stephen bennett senior meteorologist enron research london april tony hamilton meteorology manager enron research'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('spam.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df['text'],df['spam'], test_size = 0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform(classifiers, vectorizers):\n",
    "    max_score = 0\n",
    "    max_name = 0\n",
    "    for classifier in classifiers:\n",
    "        for vectorizer in vectorizers:\n",
    "        \n",
    "            # train\n",
    "            vectorize_text = vectorizer.fit_transform(xtrain)\n",
    "            classifier.fit(vectorize_text, ytrain)\n",
    "    \n",
    "            # score\n",
    "            vectorize_text = vectorizer.transform(xtest)\n",
    "            score = classifier.score(vectorize_text, ytest)\n",
    "            name = classifier.__class__.__name__ + '_with_' + vectorizer.__class__.__name__ \n",
    "            print(name, score)\n",
    "            filename = f'models/{name}.pkl'\n",
    "            pickle.dump(classifier, open(filename, 'wb'))\n",
    "            \n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_name = name\n",
    "\n",
    "    print ('===========================================')\n",
    "    print ('===========================================')\n",
    "    print (max_name, max_score)\n",
    "    print ('===========================================')\n",
    "    print ('===========================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list of various classifiers we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "        BernoulliNB(),\n",
    "        MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
    "        RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
    "        AdaBoostClassifier(),\n",
    "        BaggingClassifier(),\n",
    "        ExtraTreesClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        CalibratedClassifierCV(),\n",
    "        PassiveAggressiveClassifier(),\n",
    "        RidgeClassifier(),\n",
    "        RidgeClassifierCV(),\n",
    "        SGDClassifier(),\n",
    "        OneVsRestClassifier(SVC(kernel='linear')),\n",
    "        OneVsRestClassifier(LogisticRegression()),\n",
    "        KNeighborsClassifier(),\n",
    "        LogisticRegression()\n",
    "        \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list of various vectorizers we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = [\n",
    "        CountVectorizer(),\n",
    "        TfidfVectorizer()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform classification and save results to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB_with_CountVectorizer 0.9885864793678666\n",
      "BernoulliNB_with_TfidfVectorizer 0.9885864793678666\n",
      "MultinomialNB_with_CountVectorizer 0.9868305531167691\n",
      "MultinomialNB_with_TfidfVectorizer 0.9332748024582967\n",
      "RandomForestClassifier_with_CountVectorizer 0.9754170324846356\n",
      "RandomForestClassifier_with_TfidfVectorizer 0.9736611062335382\n",
      "AdaBoostClassifier_with_CountVectorizer 0.9683933274802459\n",
      "AdaBoostClassifier_with_TfidfVectorizer 0.9683933274802459\n",
      "BaggingClassifier_with_CountVectorizer 0.9789288849868305\n",
      "BaggingClassifier_with_TfidfVectorizer 0.9701492537313433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier_with_CountVectorizer 0.9569798068481123\n",
      "ExtraTreesClassifier_with_TfidfVectorizer 0.9561018437225637\n",
      "GradientBoostingClassifier_with_CountVectorizer 0.9604916593503073\n",
      "GradientBoostingClassifier_with_TfidfVectorizer 0.9596136962247586\n",
      "DecisionTreeClassifier_with_CountVectorizer 0.9604916593503073\n",
      "DecisionTreeClassifier_with_TfidfVectorizer 0.9587357330992098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2052: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CalibratedClassifierCV_with_CountVectorizer 0.9841966637401229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2052: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CalibratedClassifierCV_with_TfidfVectorizer 0.990342405618964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveClassifier_with_CountVectorizer 0.9850746268656716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveClassifier_with_TfidfVectorizer 0.9920983318700615\n",
      "RidgeClassifier_with_CountVectorizer 0.9420544337137841\n",
      "RidgeClassifier_with_TfidfVectorizer 0.9868305531167691\n",
      "RidgeClassifierCV_with_CountVectorizer 0.9561018437225637\n",
      "RidgeClassifierCV_with_TfidfVectorizer 0.9859525899912204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_with_CountVectorizer 0.9798068481123793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_with_TfidfVectorizer 0.9885864793678666\n",
      "OneVsRestClassifier_with_CountVectorizer 0.9850746268656716\n",
      "OneVsRestClassifier_with_TfidfVectorizer 0.9894644424934153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneVsRestClassifier_with_CountVectorizer 0.990342405618964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneVsRestClassifier_with_TfidfVectorizer 0.9824407374890255\n",
      "KNeighborsClassifier_with_CountVectorizer 0.9113257243195786\n",
      "KNeighborsClassifier_with_TfidfVectorizer 0.9771729587357331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_with_CountVectorizer 0.990342405618964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_with_TfidfVectorizer 0.9824407374890255\n",
      "===========================================\n",
      "===========================================\n",
      "PassiveAggressiveClassifier_with_TfidfVectorizer 0.9920983318700615\n",
      "===========================================\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "perform(\n",
    "    classifiers,\n",
    "    vectorizers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf = tfidf.fit(xtrain)\n",
    "pickle.dump(tfidf, open('vectors/TfidfVectorizer.pkl', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('models/PassiveAggressiveClassifier_with_TfidfVectorizer.pkl', 'rb'))\n",
    "vectorizer = pickle.load(open('vectors/TfidfVectorizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 13453)\t0.17629589784128108\n",
      "  (0, 13399)\t0.10442211172613461\n",
      "  (0, 13188)\t0.24061493978879636\n",
      "  (0, 12544)\t0.1222819769102806\n",
      "  (0, 11855)\t0.06992548671492486\n",
      "  (0, 11120)\t0.10703465189454263\n",
      "  (0, 9822)\t0.17586157246271858\n",
      "  (0, 9036)\t0.32898835604396726\n",
      "  (0, 8977)\t0.13187704191438276\n",
      "  (0, 7912)\t0.15748754002160964\n",
      "  (0, 7080)\t0.08542845836512303\n",
      "  (0, 6517)\t0.15294675088134327\n",
      "  (0, 6457)\t0.5057399007767589\n",
      "  (0, 6417)\t0.1204653218931254\n",
      "  (0, 6091)\t0.19135725037940082\n",
      "  (0, 5678)\t0.18355553966292937\n",
      "  (0, 5347)\t0.10199128984109639\n",
      "  (0, 5009)\t0.09075306283213497\n",
      "  (0, 4971)\t0.19343485617874404\n",
      "  (0, 4803)\t0.20621233244690734\n",
      "  (0, 4801)\t0.12540049904064163\n",
      "  (0, 4566)\t0.18753934355961221\n",
      "  (0, 4514)\t0.14222261926148544\n",
      "  (0, 4200)\t0.15317159244952122\n",
      "  (0, 4187)\t0.10776560695033563\n",
      "  (0, 2360)\t0.29109307095689124\n",
      "  (0, 146)\t0.16330501657674615\n"
     ]
    }
   ],
   "source": [
    "SMS = ' won a 1 week FREE membership in our $100,000 Prize Jackpot! Txt the word: C'\n",
    "ham = \"Subject: rabi de phone interview  shirley ,  let ' s act on it .  vince  - - - - - - - - - - - - - - - - - - - - - - forwarded by vince j kaminski / hou / ect on 07 / 07 / 2000  05 : 07 pm - - - - - - - - - - - - - - - - - - - - - - - - - - -  zimin lu  07 / 07 / 2000 01 : 51 pm  to : vince j kaminski / hou / ect @ ect  cc :  subject : rabi de phone interview  vince ,  we had phone interview with rabi de . my impression is good . we should invite  him for a formal interview .  he is a hands on person with wide range of experience ( energy financing ,  derivatives trading , hedging , etc ) .  he communicates very well and expressed interest in financial engineering &  modeling .  zimin\"\n",
    "\n",
    "tr = re.sub('[^a-zA-Z0-9]+', ' ',ham)\n",
    "tr = tr.lower().split()\n",
    "tr = ' '.join(list(filter(lambda text:text in words,tr)))\n",
    "\n",
    "vectorize_message = vectorizer.transform([tr])\n",
    "predict = model.predict(vectorize_message)[0]\n",
    "print(vectorize_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\n"
     ]
    }
   ],
   "source": [
    "if predict == 0:\n",
    "    print ('ham')\n",
    "else:\n",
    "    print ('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject phone interview shirley let act vince forwarded vince j vince j subject phone interview vince phone interview impression good invite formal interview person wide range experience energy financing trading hedging communicates well expressed interest financial engineering modeling'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
