{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import *\n",
    "from sklearn.dummy import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.calibration import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.svm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "text  0\n",
       "spam  0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: re : credit . com cv ' s  my feedback...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: thank you  graham pl . # 207  austin ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: re : lng may 19 decision  vince - tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: your commissions of $ 5000 per week !...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : new computer  jarod :  can you h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>Subject: re : next visit to houston  george , ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>Subject: re : brazil  fyi . this is a deal i '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5692</th>\n",
       "      <td>Subject: localized software , all languages av...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5693</th>\n",
       "      <td>Subject: re : maureen raymond - castaneda exte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5694</th>\n",
       "      <td>Subject: re : additional bloomberg terminal fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5695 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam\n",
       "0     Subject: re : credit . com cv ' s  my feedback...     0\n",
       "1     Subject: thank you  graham pl . # 207  austin ...     0\n",
       "2     Subject: re : lng may 19 decision  vince - tha...     0\n",
       "3     Subject: your commissions of $ 5000 per week !...     1\n",
       "4     Subject: re : new computer  jarod :  can you h...     0\n",
       "...                                                 ...   ...\n",
       "5690  Subject: re : next visit to houston  george , ...     0\n",
       "5691  Subject: re : brazil  fyi . this is a deal i '...     0\n",
       "5692  Subject: localized software , all languages av...     1\n",
       "5693  Subject: re : maureen raymond - castaneda exte...     0\n",
       "5694  Subject: re : additional bloomberg terminal fo...     0\n",
       "\n",
       "[5695 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56622\n"
     ]
    }
   ],
   "source": [
    "lmtzr = WordNetLemmatizer()\n",
    "with open('english.txt', 'r') as f:\n",
    "  text = f.readlines()\n",
    "eng_words_ubuntu = set([lmtzr.lemmatize(x.strip().lower().replace('\\'s', '')) for x in text] )\n",
    "stopwords = set(stopwords.words('english'))\n",
    "words = eng_words_ubuntu.difference(stopwords)\n",
    "print(len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = re.sub('[^a-zA-Z0-9]+', ' ',df['text'][0])\n",
    "tr = tr.lower().split()\n",
    "tr = ' '.join(list(filter(lambda text:text in words,tr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject credit cv feedback philip excellent cv background university chicago work experience long term capital hopefully learned something somewhat idealistic aim make bid product could really address would handle nevertheless bryan fit role seemed somewhat worked variety specific view mind would like seemed academically oriented might hard communicate work see working see leading group either would good person brainstorm forwarded bryan vince j subject credit cv could talk monday obtain feedback team thanks assistance vince j rosalinda vince j shirley bryan lon subject credit cv rosie making bring houston interview vince rosalinda vince j shirley subject credit cv vince asked forward rosie forwarded rosalinda louise rosalinda subject credit cv rosalinda work melanie doyle london two trying arrange bryan come see vince however finding difficult end would possible forward cv vince assistant sure correct person thanks help need number louise'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda text:re.sub('[^a-zA-Z0-9]+', ' ',text)).apply(lambda x: (x.lower()).split())\n",
    "df['text']= df['text'].apply(lambda text_list:' '.join(list(filter(lambda text:text in words,text_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject credit cv feedback philip excellent cv background university chicago work experience long term capital hopefully learned something somewhat idealistic aim make bid product could really address would handle nevertheless bryan fit role seemed somewhat worked variety specific view mind would like seemed academically oriented might hard communicate work see working see leading group either would good person brainstorm forwarded bryan vince j subject credit cv could talk monday obtain feedback team thanks assistance vince j rosalinda vince j shirley bryan lon subject credit cv rosie making bring houston interview vince rosalinda vince j shirley subject credit cv vince asked forward rosie forwarded rosalinda louise rosalinda subject credit cv rosalinda work melanie doyle london two trying arrange bryan come see vince however finding difficult end would possible forward cv vince assistant sure correct person thanks help need number louise'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('spam.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df['text'],df['spam'], test_size = 0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2591    0\n",
       "1713    0\n",
       "978     0\n",
       "1190    0\n",
       "2987    0\n",
       "       ..\n",
       "39      1\n",
       "2584    1\n",
       "3524    0\n",
       "2218    1\n",
       "70      0\n",
       "Name: spam, Length: 4556, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform(classifiers, vectorizers):\n",
    "    max_score = 0\n",
    "    max_name = 0\n",
    "    for classifier in classifiers:\n",
    "        for vectorizer in vectorizers:\n",
    "        \n",
    "            # train\n",
    "            vectorize_text = vectorizer.fit_transform(xtrain)\n",
    "            classifier.fit(vectorize_text, ytrain)\n",
    "\n",
    "            # score\n",
    "            vectorize_text = vectorizer.transform(xtest)\n",
    "            score = classifier.score(vectorize_text, ytest)\n",
    "            name = classifier.__class__.__name__ + ' with ' + vectorizer.__class__.__name__ \n",
    "            print(name, score)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_name = name\n",
    "    print ('===========================================')\n",
    "    print ('===========================================')\n",
    "    print (max_name, max_score)\n",
    "    print ('===========================================')\n",
    "    print ('===========================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list of various classifiers we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "        BernoulliNB(),\n",
    "        MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
    "        RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
    "        AdaBoostClassifier(),\n",
    "        BaggingClassifier(),\n",
    "        ExtraTreesClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        CalibratedClassifierCV(),\n",
    "        PassiveAggressiveClassifier(),\n",
    "        RidgeClassifier(),\n",
    "        RidgeClassifierCV(),\n",
    "        SGDClassifier(),\n",
    "        OneVsRestClassifier(SVC(kernel='linear')),\n",
    "        OneVsRestClassifier(LogisticRegression()),\n",
    "        KNeighborsClassifier()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list of various vectorizers we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = [\n",
    "        CountVectorizer(),\n",
    "        TfidfVectorizer(),\n",
    "        HashingVectorizer()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform classification and save results to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB with CountVectorizer 0.9859525899912204\n",
      "BernoulliNB with TfidfVectorizer 0.9859525899912204\n",
      "BernoulliNB with HashingVectorizer 0.7576821773485514\n",
      "RandomForestClassifier with CountVectorizer 0.9762949956101844\n",
      "RandomForestClassifier with TfidfVectorizer 0.9780509218612818\n",
      "RandomForestClassifier with HashingVectorizer 0.9508340649692713\n",
      "AdaBoostClassifier with CountVectorizer 0.9543459174714662\n",
      "AdaBoostClassifier with TfidfVectorizer 0.9578577699736611\n",
      "AdaBoostClassifier with HashingVectorizer 0.9578577699736611\n",
      "BaggingClassifier with CountVectorizer 0.9596136962247586\n",
      "BaggingClassifier with TfidfVectorizer 0.9596136962247586\n",
      "BaggingClassifier with HashingVectorizer 0.9569798068481123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier with CountVectorizer 0.9657594381035997\n",
      "ExtraTreesClassifier with TfidfVectorizer 0.9596136962247586\n",
      "ExtraTreesClassifier with HashingVectorizer 0.9429323968393327\n",
      "GradientBoostingClassifier with CountVectorizer 0.9683933274802459\n",
      "GradientBoostingClassifier with TfidfVectorizer 0.9683933274802459\n",
      "GradientBoostingClassifier with HashingVectorizer 0.9675153643546971\n",
      "DecisionTreeClassifier with CountVectorizer 0.9473222124670764\n",
      "DecisionTreeClassifier with TfidfVectorizer 0.9543459174714662\n",
      "DecisionTreeClassifier with HashingVectorizer 0.9534679543459175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2052: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CalibratedClassifierCV with CountVectorizer 0.9780509218612818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2052: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CalibratedClassifierCV with TfidfVectorizer 0.9938542581211589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2052: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CalibratedClassifierCV with HashingVectorizer 0.9894644424934153\n",
      "DummyClassifier with CountVectorizer 0.6198419666374012\n",
      "DummyClassifier with TfidfVectorizer 0.6488147497805092\n",
      "DummyClassifier with HashingVectorizer 0.6277436347673397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveClassifier with CountVectorizer 0.9824407374890255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveClassifier with TfidfVectorizer 0.9920983318700615\n",
      "PassiveAggressiveClassifier with HashingVectorizer 0.9885864793678666\n",
      "RidgeClassifier with CountVectorizer 0.9490781387181738\n",
      "RidgeClassifier with TfidfVectorizer 0.9824407374890255\n",
      "RidgeClassifier with HashingVectorizer 0.9833187006145742\n",
      "RidgeClassifierCV with CountVectorizer 0.9543459174714662\n",
      "RidgeClassifierCV with TfidfVectorizer 0.9789288849868305\n",
      "RidgeClassifierCV with HashingVectorizer 0.9824407374890255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier with CountVectorizer 0.9762949956101844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier with TfidfVectorizer 0.9912203687445127\n",
      "SGDClassifier with HashingVectorizer 0.9929762949956101\n",
      "OneVsRestClassifier with CountVectorizer 0.9824407374890255\n",
      "OneVsRestClassifier with TfidfVectorizer 0.9912203687445127\n",
      "OneVsRestClassifier with HashingVectorizer 0.9920983318700615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneVsRestClassifier with CountVectorizer 0.9868305531167691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\desktop\\project\\venv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneVsRestClassifier with TfidfVectorizer 0.9754170324846356\n"
     ]
    }
   ],
   "source": [
    "perform(\n",
    "    classifiers,\n",
    "    vectorizers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "          n_jobs=None)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the classifier with best accuracy\n",
    "Classifier = OneVsRestClassifier(SVC(kernel='linear', probability=True))\n",
    "Vectorizer = TfidfVectorizer()\n",
    "vectorize_text = Vectorizer.fit_transform(train_data.SMS)\n",
    "Classifier.fit(vectorize_text, train_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMS = ' won a 1 week FREE membership in our $100,000 Prize Jackpot! Txt the word: C'\n",
    "vectorize_message = Vectorizer.transform([SMS])\n",
    "predict = Classifier.predict(vectorize_message)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "if predict == 0:\n",
    "    print ('ham')\n",
    "else:\n",
    "    print ('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
